{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, num_inputs, hidden_dim):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.num_inputs = num_inputs\n",
    "\n",
    "        # Adjust the selector to consider all inputs\n",
    "        self.selector = nn.Sequential(\n",
    "            nn.Linear(input_dim * num_inputs, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, num_inputs)\n",
    "        )\n",
    "        \n",
    "        # Policy remains the same but is applied to each input\n",
    "        self.policy = nn.Sequential(\n",
    "            nn.Linear(input_dim, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, input_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, *inputs, temperature=1.0):\n",
    "        # Concatenate all inputs for the selector\n",
    "        concatenated_inputs = th.cat(inputs, dim=-1)\n",
    "        selector_logits = self.selector(concatenated_inputs)\n",
    "        \n",
    "        # Apply Gumbel-Softmax trick to selector logits\n",
    "        gumbel_noise = -th.log(-th.log(th.rand_like(selector_logits)))\n",
    "        sampled = F.softmax((selector_logits + gumbel_noise) / temperature, dim=-1)\n",
    "\n",
    "        # Straight-Through Estimator: hard in forward, soft in backward\n",
    "        hard_sampled = th.zeros_like(sampled).scatter_(-1, sampled.max(dim=-1, keepdim=True)[1], 1.0)\n",
    "        hard_sampled = (hard_sampled - sampled).detach() + sampled\n",
    "\n",
    "        # Process all inputs through the policy network in one batch\n",
    "        stacked_inputs = th.stack(inputs, dim=1)\n",
    "        # print(stacked_inputs)\n",
    "        # print(stacked_inputs.shape)\n",
    "        # print(hard_sampled)\n",
    "        # print(hard_sampled.shape)\n",
    "        # print((stacked_inputs * hard_sampled.unsqueeze(-1)).sum(1))\n",
    "        # concatenated_policy_inputs = stacked_inputs.view(-1, stacked_inputs.shape[-1])\n",
    "        concatenated_policy_inputs = (stacked_inputs * hard_sampled.unsqueeze(-1)).sum(1)\n",
    "        # print(concatenated_policy_inputs.shape)\n",
    "        concatenated_policy_outputs = self.policy(concatenated_policy_inputs)\n",
    "\n",
    "        # Reshape policy outputs\n",
    "        # policy_outputs = concatenated_policy_outputs.view(-1, len(inputs), *concatenated_policy_outputs.shape[1:])\n",
    "        \n",
    "        # Apply weights and sum\n",
    "        # weighted_policy_outputs = policy_outputs * hard_sampled.unsqueeze(-1).expand_as(policy_outputs)\n",
    "        # selected_x = weighted_policy_outputs.sum(dim=1)\n",
    "        selected_x = concatenated_policy_outputs\n",
    "\n",
    "        return selector_logits, selected_x\n",
    "    \n",
    "    def predict(self, *inputs):\n",
    "        concatenated_inputs = th.cat(inputs, dim=-1)\n",
    "        selector_logits = self.selector(concatenated_inputs)\n",
    "        \n",
    "        # Use argmax to find the index of the selected input\n",
    "        selected_index = th.argmax(selector_logits, dim=-1)\n",
    "\n",
    "        # Gather the selected inputs using advanced indexing\n",
    "        selected_inputs = th.stack(inputs, dim=1)  # Shape: [batch_size, num_inputs, input_dim]\n",
    "        batch_indices = th.arange(selected_inputs.size(0)).to(selected_inputs.device)\n",
    "        selected_x = selected_inputs[batch_indices, selected_index]\n",
    "\n",
    "        # Process the selected inputs through the policy network\n",
    "        policy_out = self.policy(selected_x)\n",
    "\n",
    "        return policy_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlternativeNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, num_inputs, hidden_dim):\n",
    "        super(AlternativeNet, self).__init__()\n",
    "        \n",
    "        # The input dimension is multiplied by the number of inputs\n",
    "        self.policy = nn.Sequential(\n",
    "            nn.Linear(input_dim * num_inputs, hidden_dim),  # Adjusted input dimension\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, input_dim)  # Outputting a k-dimensional vector\n",
    "        )\n",
    "        \n",
    "    def forward(self, *inputs, temperature=None):\n",
    "        # Concatenate all inputs\n",
    "        concatenated_inputs = th.cat(inputs, dim=-1)\n",
    "        \n",
    "        # Process the concatenated inputs through the policy network\n",
    "        policy_out = self.policy(concatenated_inputs)\n",
    "        \n",
    "        return None, policy_out\n",
    "    \n",
    "    def predict(self, *inputs):\n",
    "        return self.forward(*inputs)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(batch_size, vector_dim, num_vectors, device):\n",
    "    # Initialize a list to hold all vectors\n",
    "    data = []\n",
    "\n",
    "    # Generate zero-valued vectors for each input except one\n",
    "    for _ in range(num_vectors - 1):\n",
    "        zero_vectors = th.zeros(batch_size, vector_dim).to(device)\n",
    "        data.append(zero_vectors)\n",
    "\n",
    "    # Generate one vector with random values in the interval [-1, 1]\n",
    "    random_vectors = th.rand(batch_size, vector_dim).to(device)\n",
    "    data.append(random_vectors)\n",
    "\n",
    "    # Randomly shuffle the vectors in each sample and record the labels\n",
    "    labels = th.zeros(batch_size, dtype=th.long).to(device)\n",
    "    shuffled_data = []\n",
    "    for i in range(batch_size):\n",
    "        sample = [d[i] for d in data]\n",
    "        random_index = np.random.randint(num_vectors)\n",
    "        sample[random_index], sample[-1] = sample[-1], sample[random_index]\n",
    "        shuffled_data.append(sample)\n",
    "        labels[i] = random_index\n",
    "\n",
    "    # Unzip the list of tuples back into separate tensors\n",
    "    data = [th.stack(t) for t in zip(*shuffled_data)]\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/5000], Loss: 0.3385\n",
      "Epoch [40/5000], Loss: 0.2147\n",
      "Epoch [60/5000], Loss: 0.2133\n",
      "Epoch [80/5000], Loss: 0.1639\n",
      "Epoch [100/5000], Loss: 0.1175\n",
      "Epoch [120/5000], Loss: 0.1093\n",
      "Epoch [140/5000], Loss: 0.0851\n",
      "Epoch [160/5000], Loss: 0.0985\n",
      "Epoch [180/5000], Loss: 0.0843\n",
      "Epoch [200/5000], Loss: 0.0778\n",
      "Epoch [220/5000], Loss: 0.0833\n",
      "Epoch [240/5000], Loss: 0.0822\n",
      "Epoch [260/5000], Loss: 0.0742\n",
      "Epoch [280/5000], Loss: 0.0751\n",
      "Epoch [300/5000], Loss: 0.0783\n",
      "Epoch [320/5000], Loss: 0.0885\n",
      "Epoch [340/5000], Loss: 0.0895\n",
      "Epoch [360/5000], Loss: 0.0764\n",
      "Epoch [380/5000], Loss: 0.0935\n",
      "Epoch [400/5000], Loss: 0.0813\n",
      "Epoch [420/5000], Loss: 0.0824\n",
      "Epoch [440/5000], Loss: 0.0806\n",
      "Epoch [460/5000], Loss: 0.0783\n",
      "Epoch [480/5000], Loss: 0.0840\n",
      "Epoch [500/5000], Loss: 0.0805\n",
      "Epoch [520/5000], Loss: 0.0758\n",
      "Epoch [540/5000], Loss: 0.0946\n",
      "Epoch [560/5000], Loss: 0.0869\n",
      "Epoch [580/5000], Loss: 0.0737\n",
      "Epoch [600/5000], Loss: 0.0861\n",
      "Epoch [620/5000], Loss: 0.0849\n",
      "Epoch [640/5000], Loss: 0.0805\n",
      "Epoch [660/5000], Loss: 0.0762\n",
      "Epoch [680/5000], Loss: 0.0678\n",
      "Epoch [700/5000], Loss: 0.0667\n",
      "Epoch [720/5000], Loss: 0.0661\n",
      "Epoch [740/5000], Loss: 0.0636\n",
      "Epoch [760/5000], Loss: 0.0630\n",
      "Epoch [780/5000], Loss: 0.0468\n",
      "Epoch [800/5000], Loss: 0.0448\n",
      "Epoch [820/5000], Loss: 0.0431\n",
      "Epoch [840/5000], Loss: 0.0370\n",
      "Epoch [860/5000], Loss: 0.0446\n",
      "Epoch [880/5000], Loss: 0.0266\n",
      "Epoch [900/5000], Loss: 0.0214\n",
      "Epoch [920/5000], Loss: 0.0172\n",
      "Epoch [940/5000], Loss: 0.0190\n",
      "Epoch [960/5000], Loss: 0.0090\n",
      "Epoch [980/5000], Loss: 0.0167\n",
      "Epoch [1000/5000], Loss: 0.0129\n",
      "Epoch [1020/5000], Loss: 0.0067\n",
      "Epoch [1040/5000], Loss: 0.0067\n",
      "Epoch [1060/5000], Loss: 0.0125\n",
      "Epoch [1080/5000], Loss: 0.0034\n",
      "Epoch [1100/5000], Loss: 0.0112\n",
      "Epoch [1120/5000], Loss: 0.0065\n",
      "Epoch [1140/5000], Loss: 0.0091\n",
      "Epoch [1160/5000], Loss: 0.0042\n",
      "Epoch [1180/5000], Loss: 0.0025\n",
      "Epoch [1200/5000], Loss: 0.0024\n",
      "Epoch [1220/5000], Loss: 0.0044\n",
      "Epoch [1240/5000], Loss: 0.0077\n",
      "Epoch [1260/5000], Loss: 0.0077\n",
      "Epoch [1280/5000], Loss: 0.0158\n",
      "Epoch [1300/5000], Loss: 0.0066\n",
      "Epoch [1320/5000], Loss: 0.0046\n",
      "Epoch [1340/5000], Loss: 0.0075\n",
      "Epoch [1360/5000], Loss: 0.0069\n",
      "Epoch [1380/5000], Loss: 0.0074\n",
      "Epoch [1400/5000], Loss: 0.0019\n",
      "Epoch [1420/5000], Loss: 0.0025\n",
      "Epoch [1440/5000], Loss: 0.0074\n",
      "Epoch [1460/5000], Loss: 0.0028\n",
      "Epoch [1480/5000], Loss: 0.0018\n",
      "Epoch [1500/5000], Loss: 0.0064\n",
      "Epoch [1520/5000], Loss: 0.0059\n",
      "Epoch [1540/5000], Loss: 0.0046\n",
      "Epoch [1560/5000], Loss: 0.0028\n",
      "Epoch [1580/5000], Loss: 0.0088\n",
      "Epoch [1600/5000], Loss: 0.0029\n",
      "Epoch [1620/5000], Loss: 0.0124\n",
      "Epoch [1640/5000], Loss: 0.0077\n",
      "Epoch [1660/5000], Loss: 0.0008\n",
      "Epoch [1680/5000], Loss: 0.0016\n",
      "Epoch [1700/5000], Loss: 0.0008\n",
      "Epoch [1720/5000], Loss: 0.0078\n",
      "Epoch [1740/5000], Loss: 0.0049\n",
      "Epoch [1760/5000], Loss: 0.0065\n",
      "Epoch [1780/5000], Loss: 0.0107\n",
      "Epoch [1800/5000], Loss: 0.0071\n",
      "Epoch [1820/5000], Loss: 0.0065\n",
      "Epoch [1840/5000], Loss: 0.0063\n",
      "Epoch [1860/5000], Loss: 0.0043\n",
      "Epoch [1880/5000], Loss: 0.0049\n",
      "Epoch [1900/5000], Loss: 0.0024\n",
      "Epoch [1920/5000], Loss: 0.0007\n",
      "Epoch [1940/5000], Loss: 0.0063\n",
      "Epoch [1960/5000], Loss: 0.0072\n",
      "Epoch [1980/5000], Loss: 0.0052\n",
      "Epoch [2000/5000], Loss: 0.0005\n",
      "Epoch [2020/5000], Loss: 0.0004\n",
      "Epoch [2040/5000], Loss: 0.0096\n",
      "Epoch [2060/5000], Loss: 0.0005\n",
      "Epoch [2080/5000], Loss: 0.0021\n",
      "Epoch [2100/5000], Loss: 0.0022\n",
      "Epoch [2120/5000], Loss: 0.0007\n",
      "Epoch [2140/5000], Loss: 0.0097\n",
      "Epoch [2160/5000], Loss: 0.0031\n",
      "Epoch [2180/5000], Loss: 0.0002\n",
      "Epoch [2200/5000], Loss: 0.0022\n",
      "Epoch [2220/5000], Loss: 0.0021\n",
      "Epoch [2240/5000], Loss: 0.0020\n",
      "Epoch [2260/5000], Loss: 0.0020\n",
      "Epoch [2280/5000], Loss: 0.0007\n",
      "Epoch [2300/5000], Loss: 0.0012\n",
      "Epoch [2320/5000], Loss: 0.0016\n",
      "Epoch [2340/5000], Loss: 0.0052\n",
      "Epoch [2360/5000], Loss: 0.0025\n",
      "Epoch [2380/5000], Loss: 0.0024\n",
      "Epoch [2400/5000], Loss: 0.0023\n",
      "Epoch [2420/5000], Loss: 0.0002\n",
      "Epoch [2440/5000], Loss: 0.0013\n",
      "Epoch [2460/5000], Loss: 0.0054\n",
      "Epoch [2480/5000], Loss: 0.0043\n",
      "Epoch [2500/5000], Loss: 0.0001\n",
      "Epoch [2520/5000], Loss: 0.0036\n",
      "Epoch [2540/5000], Loss: 0.0001\n",
      "Epoch [2560/5000], Loss: 0.0000\n",
      "Epoch [2580/5000], Loss: 0.0000\n",
      "Epoch [2600/5000], Loss: 0.0001\n",
      "Epoch [2620/5000], Loss: 0.0050\n",
      "Epoch [2640/5000], Loss: 0.0021\n",
      "Epoch [2660/5000], Loss: 0.0031\n",
      "Epoch [2680/5000], Loss: 0.0029\n",
      "Epoch [2700/5000], Loss: 0.0020\n",
      "Epoch [2720/5000], Loss: 0.0022\n",
      "Epoch [2740/5000], Loss: 0.0068\n",
      "Epoch [2760/5000], Loss: 0.0031\n",
      "Epoch [2780/5000], Loss: 0.0074\n",
      "Epoch [2800/5000], Loss: 0.0008\n",
      "Epoch [2820/5000], Loss: 0.0043\n",
      "Epoch [2840/5000], Loss: 0.0011\n",
      "Epoch [2860/5000], Loss: 0.0000\n",
      "Epoch [2880/5000], Loss: 0.0040\n",
      "Epoch [2900/5000], Loss: 0.0084\n",
      "Epoch [2920/5000], Loss: 0.0000\n",
      "Epoch [2940/5000], Loss: 0.0015\n",
      "Epoch [2960/5000], Loss: 0.0079\n",
      "Epoch [2980/5000], Loss: 0.0010\n",
      "Epoch [3000/5000], Loss: 0.0015\n",
      "Epoch [3020/5000], Loss: 0.0052\n",
      "Epoch [3040/5000], Loss: 0.0012\n",
      "Epoch [3060/5000], Loss: 0.0018\n",
      "Epoch [3080/5000], Loss: 0.0000\n",
      "Epoch [3100/5000], Loss: 0.0000\n",
      "Epoch [3120/5000], Loss: 0.0012\n",
      "Epoch [3140/5000], Loss: 0.0000\n",
      "Epoch [3160/5000], Loss: 0.0063\n",
      "Epoch [3180/5000], Loss: 0.0014\n",
      "Epoch [3200/5000], Loss: 0.0000\n",
      "Epoch [3220/5000], Loss: 0.0000\n",
      "Epoch [3240/5000], Loss: 0.0052\n",
      "Epoch [3260/5000], Loss: 0.0022\n",
      "Epoch [3280/5000], Loss: 0.0039\n",
      "Epoch [3300/5000], Loss: 0.0000\n",
      "Epoch [3320/5000], Loss: 0.0000\n",
      "Epoch [3340/5000], Loss: 0.0000\n",
      "Epoch [3360/5000], Loss: 0.0037\n",
      "Epoch [3380/5000], Loss: 0.0000\n",
      "Epoch [3400/5000], Loss: 0.0024\n",
      "Epoch [3420/5000], Loss: 0.0000\n",
      "Epoch [3440/5000], Loss: 0.0000\n",
      "Epoch [3460/5000], Loss: 0.0000\n",
      "Epoch [3480/5000], Loss: 0.0008\n",
      "Epoch [3500/5000], Loss: 0.0000\n",
      "Epoch [3520/5000], Loss: 0.0000\n",
      "Epoch [3540/5000], Loss: 0.0000\n",
      "Epoch [3560/5000], Loss: 0.0061\n",
      "Epoch [3580/5000], Loss: 0.0000\n",
      "Epoch [3600/5000], Loss: 0.0000\n",
      "Epoch [3620/5000], Loss: 0.0000\n",
      "Epoch [3640/5000], Loss: 0.0012\n",
      "Epoch [3660/5000], Loss: 0.0030\n",
      "Epoch [3680/5000], Loss: 0.0000\n",
      "Epoch [3700/5000], Loss: 0.0009\n",
      "Epoch [3720/5000], Loss: 0.0000\n",
      "Epoch [3740/5000], Loss: 0.0000\n",
      "Epoch [3760/5000], Loss: 0.0001\n",
      "Epoch [3780/5000], Loss: 0.0000\n",
      "Epoch [3800/5000], Loss: 0.0000\n",
      "Epoch [3820/5000], Loss: 0.0000\n",
      "Epoch [3840/5000], Loss: 0.0000\n",
      "Epoch [3860/5000], Loss: 0.0016\n",
      "Epoch [3880/5000], Loss: 0.0000\n",
      "Epoch [3900/5000], Loss: 0.0000\n",
      "Epoch [3920/5000], Loss: 0.0010\n",
      "Epoch [3940/5000], Loss: 0.0000\n",
      "Epoch [3960/5000], Loss: 0.0000\n",
      "Epoch [3980/5000], Loss: 0.0000\n",
      "Epoch [4000/5000], Loss: 0.0000\n",
      "Epoch [4020/5000], Loss: 0.0012\n",
      "Epoch [4040/5000], Loss: 0.0000\n",
      "Epoch [4060/5000], Loss: 0.0000\n",
      "Epoch [4080/5000], Loss: 0.0000\n",
      "Epoch [4100/5000], Loss: 0.0035\n",
      "Epoch [4120/5000], Loss: 0.0031\n",
      "Epoch [4140/5000], Loss: 0.0000\n",
      "Epoch [4160/5000], Loss: 0.0000\n",
      "Epoch [4180/5000], Loss: 0.0000\n",
      "Epoch [4200/5000], Loss: 0.0000\n",
      "Epoch [4220/5000], Loss: 0.0000\n",
      "Epoch [4240/5000], Loss: 0.0010\n",
      "Epoch [4260/5000], Loss: 0.0012\n",
      "Epoch [4280/5000], Loss: 0.0015\n",
      "Epoch [4300/5000], Loss: 0.0000\n",
      "Epoch [4320/5000], Loss: 0.0014\n",
      "Epoch [4340/5000], Loss: 0.0042\n",
      "Epoch [4360/5000], Loss: 0.0000\n",
      "Epoch [4380/5000], Loss: 0.0000\n",
      "Epoch [4400/5000], Loss: 0.0000\n",
      "Epoch [4420/5000], Loss: 0.0000\n",
      "Epoch [4440/5000], Loss: 0.0000\n",
      "Epoch [4460/5000], Loss: 0.0011\n",
      "Epoch [4480/5000], Loss: 0.0000\n",
      "Epoch [4500/5000], Loss: 0.0000\n",
      "Epoch [4520/5000], Loss: 0.0004\n",
      "Epoch [4540/5000], Loss: 0.0000\n",
      "Epoch [4560/5000], Loss: 0.0000\n",
      "Epoch [4580/5000], Loss: 0.0000\n",
      "Epoch [4600/5000], Loss: 0.0000\n",
      "Epoch [4620/5000], Loss: 0.0000\n",
      "Epoch [4640/5000], Loss: 0.0009\n",
      "Epoch [4660/5000], Loss: 0.0035\n",
      "Epoch [4680/5000], Loss: 0.0047\n",
      "Epoch [4700/5000], Loss: 0.0000\n",
      "Epoch [4720/5000], Loss: 0.0000\n",
      "Epoch [4740/5000], Loss: 0.0000\n",
      "Epoch [4760/5000], Loss: 0.0033\n",
      "Epoch [4780/5000], Loss: 0.0000\n",
      "Epoch [4800/5000], Loss: 0.0013\n",
      "Epoch [4820/5000], Loss: 0.0000\n",
      "Epoch [4840/5000], Loss: 0.0036\n",
      "Epoch [4860/5000], Loss: 0.0000\n",
      "Epoch [4880/5000], Loss: 0.0000\n",
      "Epoch [4900/5000], Loss: 0.0000\n",
      "Epoch [4920/5000], Loss: 0.0000\n",
      "Epoch [4940/5000], Loss: 0.0000\n",
      "Epoch [4960/5000], Loss: 0.0000\n",
      "Epoch [4980/5000], Loss: 0.0000\n",
      "Epoch [5000/5000], Loss: 0.0030\n",
      "Training Complete\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "batch_size = 32\n",
    "vector_dim = 5\n",
    "hidden_dim = 32\n",
    "num_vectors = 25  # Number of input vectors per sample\n",
    "learning_rate = 0.001\n",
    "num_epochs = 5000\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Network, Loss, and Optimizer\n",
    "net = Net(input_dim=vector_dim, num_inputs=num_vectors, hidden_dim=hidden_dim).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "net_losses = []\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    net.train()\n",
    "\n",
    "    # Generate data and labels\n",
    "    inputs, labels = generate_data(batch_size, vector_dim, num_vectors, device)\n",
    "\n",
    "    # Forward pass: Unpack the inputs list into separate arguments\n",
    "    selector_logits, policy_out = net(*inputs)\n",
    "\n",
    "    # Prepare targets based on labels\n",
    "    targets = th.stack([inputs[labels[i]][i] for i in range(batch_size)])\n",
    "\n",
    "    # Compute loss\n",
    "    loss = criterion(policy_out, targets)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "        with th.no_grad():\n",
    "            inputs, labels = generate_data(batch_size, vector_dim, num_vectors, device)\n",
    "            eval_outputs = net.predict(*inputs)\n",
    "            targets = th.stack([inputs[labels[i]][i] for i in range(batch_size)])\n",
    "            net_losses.append(criterion(eval_outputs, targets).item())\n",
    "\n",
    "print(\"Training Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.       0.       0.       0.       0.      ]]\n",
      "\n",
      " [[0.       0.       0.       0.       0.      ]]\n",
      "\n",
      " [[0.       0.       0.       0.       0.      ]]\n",
      "\n",
      " [[0.       0.       0.       0.       0.      ]]\n",
      "\n",
      " [[0.       0.       0.       0.       0.      ]]\n",
      "\n",
      " [[0.       0.       0.       0.       0.      ]]\n",
      "\n",
      " [[0.       0.       0.       0.       0.      ]]\n",
      "\n",
      " [[0.       0.       0.       0.       0.      ]]\n",
      "\n",
      " [[0.       0.       0.       0.       0.      ]]\n",
      "\n",
      " [[0.       0.       0.       0.       0.      ]]\n",
      "\n",
      " [[0.       0.       0.       0.       0.      ]]\n",
      "\n",
      " [[0.       0.       0.       0.       0.      ]]\n",
      "\n",
      " [[0.       0.       0.       0.       0.      ]]\n",
      "\n",
      " [[0.       0.       0.       0.       0.      ]]\n",
      "\n",
      " [[0.       0.       0.       0.       0.      ]]\n",
      "\n",
      " [[0.       0.       0.       0.       0.      ]]\n",
      "\n",
      " [[0.193993 0.811515 0.144071 0.434177 0.518576]]\n",
      "\n",
      " [[0.       0.       0.       0.       0.      ]]\n",
      "\n",
      " [[0.       0.       0.       0.       0.      ]]\n",
      "\n",
      " [[0.       0.       0.       0.       0.      ]]\n",
      "\n",
      " [[0.       0.       0.       0.       0.      ]]\n",
      "\n",
      " [[0.       0.       0.       0.       0.      ]]\n",
      "\n",
      " [[0.       0.       0.       0.       0.      ]]\n",
      "\n",
      " [[0.       0.       0.       0.       0.      ]]\n",
      "\n",
      " [[0.       0.       0.       0.       0.      ]]]\n",
      "[16]\n",
      "\n",
      "[[0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.999 0.    0.    0.    0.    0.    0.    0.\n",
      "  0.   ]]\n",
      "[[0.191152 0.812163 0.140085 0.43097  0.516896]]\n",
      "[ True]\n"
     ]
    }
   ],
   "source": [
    "inputs, label = generate_data(1, vector_dim, num_vectors, device)\n",
    "selector_logits, policy_out = net(*inputs, temperature=1.0)\n",
    "\n",
    "print(th.stack(inputs, dim=0).detach().cpu().numpy().round(6))\n",
    "print(label.detach().cpu().numpy())\n",
    "print()\n",
    "print(F.softmax(selector_logits, dim=-1).detach().cpu().numpy().round(3))\n",
    "print(policy_out.detach().cpu().numpy().round(6))\n",
    "print(label.detach().cpu().numpy() == np.argmax(selector_logits.detach().cpu().numpy().round(6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00179906], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def compute_normalized_entropy(logits):\n",
    "    # Apply softmax to convert logits to probabilities\n",
    "    probabilities = F.softmax(logits, dim=-1)\n",
    "\n",
    "    # Calculate entropy\n",
    "    log_probabilities = th.log(probabilities)\n",
    "    entropy = -th.sum(probabilities * log_probabilities, dim=-1)\n",
    "\n",
    "    # Determine the number of classes from logits\n",
    "    num_classes = logits.shape[-1]\n",
    "\n",
    "    # Normalize entropy so that max entropy (uniform distribution) is 1\n",
    "    normalized_entropy = entropy / th.log(th.tensor(float(num_classes)))\n",
    "\n",
    "    return normalized_entropy\n",
    "\n",
    "# Example usage in your training loop\n",
    "# Assume selector_logits is the output of your network\n",
    "normalized_entropy = compute_normalized_entropy(selector_logits)\n",
    "normalized_entropy.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(net_losses)\n",
    "plt.plot(alt_net_losses)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rew_curr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

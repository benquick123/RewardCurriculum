{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/miniconda3/envs/rew_curr/lib/python3.10/site-packages/glfw/__init__.py:916: GLFWError: (65544) b'X11: The DISPLAY environment variable is missing'\n",
      "  warnings.warn(message, GLFWError)\n",
      "<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n",
      "/home/benjamin/miniconda3/envs/rew_curr/lib/python3.10/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/home/benjamin/miniconda3/envs/rew_curr/lib/python3.10/site-packages/torch/utils/tensorboard/__init__.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  ) < LooseVersion(\"1.15\"):\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/benjamin/RewardCurriculum/\")\n",
    "\n",
    "import gymnasium as gym\n",
    "import panda_gym\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from utils.configs import get_config\n",
    "from utils.env_wrappers import make_vec_env, get_env\n",
    "from argparse import Namespace\n",
    "import cv2\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/benjamin/RewardCurriculum\")\n",
    "folder_path = \"/home/benjamin/RewardCurriculum/results/panda/dense_PandaPickAndPlaceDense-v3_sac_singletask_0\"\n",
    "\n",
    "args = Namespace()\n",
    "args.env_name = json.load(open(os.path.join(folder_path, \"config.json\"), \"r\"))[\"environment\"][\"env_name\"]\n",
    "args.seed = json.load(open(os.path.join(folder_path, \"config.json\"), \"r\"))[\"seed\"]\n",
    "args.config_path = os.path.join(folder_path, \"config_original.json\")\n",
    "\n",
    "remaining_args = [\"--environment.wrapper_kwargs.0.reward_threshold\", \"-0.05\"]\n",
    "# remaining_args.__setattr__[] = \"-0.05\"\n",
    "config = get_config(args.config_path, args, remaining_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/miniconda3/envs/rew_curr/lib/python3.10/site-packages/glfw/__init__.py:916: GLFWError: (65544) b'X11: The DISPLAY environment variable is missing'\n",
      "  warnings.warn(message, GLFWError)\n",
      "<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n",
      "/home/benjamin/miniconda3/envs/rew_curr/lib/python3.10/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/home/benjamin/miniconda3/envs/rew_curr/lib/python3.10/site-packages/torch/utils/tensorboard/__init__.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  ) < LooseVersion(\"1.15\"):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argv[0]=--background_color_red=0.8745098114013672\n",
      "argv[1]=--background_color_green=0.21176470816135406\n",
      "argv[2]=--background_color_blue=0.1764705926179886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Sep 15 2023 11:13:12\n"
     ]
    }
   ],
   "source": [
    "make_env_fn = lambda wrappers, wrapper_kwargs, ignore_keyword=\"ignore\" : get_env(config[\"environment\"][\"env_name\"], wrappers=wrappers, wrapper_kwargs=wrapper_kwargs, ignore_keyword=ignore_keyword)\n",
    "env = make_vec_env(make_env_fn, \n",
    "                    n_envs=config[\"environment\"][\"n_envs\"], \n",
    "                    env_kwargs={\"wrappers\": config[\"environment\"][\"wrappers\"], \"wrapper_kwargs\": config[\"environment\"][\"wrapper_kwargs\"]},\n",
    "                    monitor_kwargs={\"allow_early_resets\": True},\n",
    "                    seed=config[\"seed\"], vec_env_cls=SubprocVecEnv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MultiInputPolicy.__init__() got an unexpected keyword argument 'use_retrospective_loss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# learner = config[\"learner_class\"].load(os.path.join(folder_path, \"evaluations\", \"best_model.zip\"), env=env)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m learner \u001b[39m=\u001b[39m config[\u001b[39m\"\u001b[39;49m\u001b[39mlearner_class\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mload(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(folder_path, \u001b[39m\"\u001b[39;49m\u001b[39mevaluations\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mbest_model.zip\u001b[39;49m\u001b[39m\"\u001b[39;49m), env\u001b[39m=\u001b[39;49menv)\n",
      "File \u001b[0;32m~/miniconda3/envs/rew_curr/lib/python3.10/site-packages/stable_baselines3/common/base_class.py:741\u001b[0m, in \u001b[0;36mBaseAlgorithm.load\u001b[0;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[1;32m    739\u001b[0m model\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m.\u001b[39mupdate(data)\n\u001b[1;32m    740\u001b[0m model\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m\u001b[39m.\u001b[39mupdate(kwargs)\n\u001b[0;32m--> 741\u001b[0m model\u001b[39m.\u001b[39;49m_setup_model()\n\u001b[1;32m    743\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    744\u001b[0m     \u001b[39m# put state_dicts back in place\u001b[39;00m\n\u001b[1;32m    745\u001b[0m     model\u001b[39m.\u001b[39mset_parameters(params, exact_match\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, device\u001b[39m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/RewardCurriculum/rl_algorithms/sac.py:59\u001b[0m, in \u001b[0;36mSAC._setup_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m     observation_space \u001b[39m=\u001b[39m deepcopy(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mobservation_space)\n\u001b[1;32m     57\u001b[0m     observation_space[\u001b[39m\"\u001b[39m\u001b[39mobservation\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m spaces\u001b[39m.\u001b[39mBox(\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf, np\u001b[39m.\u001b[39minf, shape\u001b[39m=\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menv\u001b[39m.\u001b[39mobservation_space[\u001b[39m\"\u001b[39m\u001b[39mobservation\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscheduler\u001b[39m.\u001b[39mreward_dim, ), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32)\n\u001b[0;32m---> 59\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy_class(  \u001b[39m# pytype:disable=not-instantiable\u001b[39;49;00m\n\u001b[1;32m     60\u001b[0m     observation_space,\n\u001b[1;32m     61\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maction_space,\n\u001b[1;32m     62\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlr_schedule,\n\u001b[1;32m     63\u001b[0m     use_retrospective_loss\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muse_retrospective_loss,\n\u001b[1;32m     64\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpolicy_kwargs,  \u001b[39m# pytype:disable=not-instantiable\u001b[39;49;00m\n\u001b[1;32m     65\u001b[0m )\n\u001b[1;32m     66\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpolicy\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m     68\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_aliases()\n",
      "\u001b[0;31mTypeError\u001b[0m: MultiInputPolicy.__init__() got an unexpected keyword argument 'use_retrospective_loss'"
     ]
    }
   ],
   "source": [
    "# learner = config[\"learner_class\"].load(os.path.join(folder_path, \"evaluations\", \"best_model.zip\"), env=env)\n",
    "learner = config[\"learner_class\"].load(os.path.join(folder_path, \"evaluations\", \"best_model.zip\"), env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_video(video_output_path, env, learner, task=None):\n",
    "    if task is None:\n",
    "        task = np.zeros((1, learner.scheduler.reward_dim))\n",
    "        task[:, -1] = 1\n",
    "    obs = env.reset()\n",
    "\n",
    "    terminated = False\n",
    "    render_imgs = []\n",
    "    while not terminated:\n",
    "        # obs = obs.reshape(1, -1)\n",
    "        act = learner.predict(obs, task=task)[0]\n",
    "        \n",
    "        obs, reward, terminated, info = env.step(act)\n",
    "        # print(reward)\n",
    "        \n",
    "        render_imgs.append(env.render())\n",
    "        \n",
    "    height, width, _ = render_imgs[0].shape\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(video_output_path, fourcc=fourcc, fps=10, frameSize=(width, height))\n",
    "\n",
    "    for frame in render_imgs:\n",
    "        out.write(frame)\n",
    "        \n",
    "    out.release()\n",
    "    \n",
    "    os.system(f\"ffmpeg -hide_banner -loglevel error -i {video_output_path} -vcodec libx264 video.mp4\")\n",
    "    os.system(f\"mv video.mp4 {video_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls><source src=\"/home/benjamin/RewardCurriculum/results/panda/dense_PandaPickAndPlaceDense-v3_sac_singletask_0/video.mp4\" type=\"video/mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_path = os.path.join(folder_path, \"video.mp4\")\n",
    "record_video(video_path, env, learner)\n",
    "HTML(f'<video alt=\"test\" controls><source src=\"{video_path}\" type=\"video/mp4\"></video>')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rew_curr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

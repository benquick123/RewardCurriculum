{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/miniconda3/envs/rew_curr/lib/python3.10/site-packages/glfw/__init__.py:916: GLFWError: (65544) b'X11: The DISPLAY environment variable is missing'\n",
      "  warnings.warn(message, GLFWError)\n",
      "<frozen importlib._bootstrap>:283: DeprecationWarning: the load_module() method is deprecated and slated for removal in Python 3.12; use exec_module() instead\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/benjamin/RewardCurriculum/\")\n",
    "\n",
    "import os\n",
    "os.system(\"export MKL_SERVICE_FORCE_INTEL=1\")\n",
    "\n",
    "import gymnasium as gym\n",
    "import panda_gym\n",
    "from stable_baselines3.common.vec_env import SubprocVecEnv, DummyVecEnv\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "from copy import deepcopy\n",
    "from utils.configs import get_config\n",
    "from utils.env_wrappers import make_vec_env, get_env\n",
    "from argparse import Namespace\n",
    "import cv2\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/home/benjamin/RewardCurriculum\")\n",
    "folder_path = \"/home/benjamin/RewardCurriculum/results/panda_pick_and_place_obstacle_long/2024-05-21_17-06-37_PandaMultiRewardPickAndPlaceObstacleDense-v3_tqc_sacx_4\"\n",
    "\n",
    "args = Namespace()\n",
    "args.env_name = json.load(open(os.path.join(folder_path, \"config.json\"), \"r\"))[\"environment\"][\"env_name\"]\n",
    "args.seed = json.load(open(os.path.join(folder_path, \"config.json\"), \"r\"))[\"seed\"]\n",
    "args.config_path = os.path.join(folder_path, \"config_original.json\")\n",
    "args.continue_from = None\n",
    "\n",
    "remaining_args = [\"--environment.wrapper_kwargs.0.reward_threshold\", \"-0.05\"]\n",
    "# remaining_args.__setattr__[] = \"-0.05\"\n",
    "config = get_config(args.config_path, args, remaining_args)\n",
    "config[\"environment\"][\"wrappers\"] += [\"SingleTaskRewardWrapper\"]\n",
    "config[\"environment\"][\"wrapper_kwargs\"] += [{}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argv[0]=--background_color_red=0.8745098114013672\n",
      "argv[1]=--background_color_green=0.21176470816135406\n",
      "argv[2]=--background_color_blue=0.1764705926179886\n"
     ]
    }
   ],
   "source": [
    "make_env_fn = lambda wrappers, wrapper_kwargs, ignore_keyword=\"ignore\" : get_env(config[\"environment\"][\"env_name\"], wrappers=wrappers, wrapper_kwargs=wrapper_kwargs, ignore_keyword=ignore_keyword)\n",
    "env = make_vec_env(make_env_fn, \n",
    "                    n_envs=config[\"environment\"][\"n_envs\"], \n",
    "                    env_kwargs={\"wrappers\": config[\"environment\"][\"wrappers\"], \"wrapper_kwargs\": config[\"environment\"][\"wrapper_kwargs\"]},\n",
    "                    monitor_kwargs={\"allow_early_resets\": True},\n",
    "                    seed=config[\"seed\"], vec_env_cls=DummyVecEnv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner = config[\"learner_class\"].load(os.path.join(folder_path, \"evaluations\", \"best_model.zip\"), env=env)\n",
    "learner = config[\"learner_class\"].load(os.path.join(folder_path, \"evaluations\", \"best_model.zip\"), env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_video(video_output_path, env, learner, task=None):\n",
    "    if task is None:\n",
    "        weights = np.zeros((1, learner.scheduler.reward_dim))\n",
    "        weights[:, -1] = 1\n",
    "    obs = env.reset()\n",
    "\n",
    "    terminated = False\n",
    "    render_imgs = []\n",
    "    while not terminated:\n",
    "        # obs = obs.reshape(1, -1)\n",
    "        # print(obs)\n",
    "        act = learner.predict(obs, weights=weights)[0]\n",
    "\n",
    "        obs, reward, terminated, info = env.step(act)\n",
    "        # print(reward)\n",
    "        \n",
    "        render_imgs.append(env.render())\n",
    "        \n",
    "    print(reward)\n",
    "    height, width, _ = render_imgs[0].shape\n",
    "\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    out = cv2.VideoWriter(video_output_path, fourcc=fourcc, fps=10, frameSize=(width, height))\n",
    "\n",
    "    for frame in render_imgs:\n",
    "        out.write(frame)\n",
    "        \n",
    "    out.release()\n",
    "    \n",
    "    os.system(f\"ffmpeg -hide_banner -loglevel error -i {video_output_path} -vcodec libx264 video.mp4\")\n",
    "    os.system(f\"mv video.mp4 {video_output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<video alt=\"test\" controls><source src=\"/home/benjamin/RewardCurriculum/results/panda_pick_and_place_obstacle_long/2024-05-21_17-06-37_PandaMultiRewardPickAndPlaceObstacleDense-v3_tqc_sacx_4/video.mp4\" type=\"video/mp4\"></video>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_path = os.path.join(folder_path, \"video.mp4\")\n",
    "record_video(video_path, env, learner)\n",
    "HTML(f'<video alt=\"test\" controls><source src=\"{video_path}\" type=\"video/mp4\"></video>')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import panda_gym\n",
    "import gymnasium as gym\n",
    "\n",
    "env = gym.make(\"PandaPickAndPlaceDense-v3\", renderer=\"OpenGL\")\n",
    "obs = env.reset()\n",
    "env.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rew_curr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict, OrderedDict\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "from scipy import stats\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our setup results paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH = \"../results/panda_stack_long\"\n",
    "LOGS_TEMPLATE_PATH = os.path.join(RESULTS_PATH, \"%s\", \"tb\", \"TQC_1\")\n",
    "\n",
    "LOG_PATH_LIST = [LOGS_TEMPLATE_PATH % folder for folder in os.listdir(RESULTS_PATH) if os.path.isdir(os.path.join(RESULTS_PATH, folder))]\n",
    "LOG_PATH_LIST = sorted([os.path.join(log_path, os.listdir(log_path)[0]) for log_path in LOG_PATH_LIST if os.path.exists(log_path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = defaultdict(dict)\n",
    "all_experiment_combinations = set()\n",
    "tb_keys = [\"eval/success_rate\"]\n",
    "\n",
    "for filepath in LOG_PATH_LIST:\n",
    "    config = json.load(open(os.path.join(\"/\".join(filepath.split(\"/\")[:-3]), \"config.json\"), \"r\"))\n",
    "    num_steps = config[\"train_kwargs\"][\"total_timesteps\"]\n",
    "    \n",
    "    run_name = filepath.split(\"/\")[-4]\n",
    "    baseline_type = run_name.split(\"_\")[4]\n",
    "    environment = \"_\".join(run_name.split(\"_\")[-4:-3])\n",
    "    \n",
    "    ea = event_accumulator.EventAccumulator(filepath, size_guidance={\"scalars\": 0})\n",
    "    ea.Reload()\n",
    "    \n",
    "    for tb_key in tb_keys:\n",
    "        if environment + \"-\" + tb_key not in results_dict[baseline_type]:\n",
    "            results_dict[baseline_type][environment + \"-\" + tb_key] = []\n",
    "        \n",
    "        scalars = [scalar.value for scalar in ea.Scalars(tb_key)]\n",
    "        scalars = np.interp(np.linspace(0, len(scalars), 100), np.arange(len(scalars)), scalars).tolist()\n",
    "        \n",
    "        results_dict[baseline_type][environment + \"-\" + tb_key].append(scalars)\n",
    "    \n",
    "for baseline_type in results_dict.keys():\n",
    "    for environment in results_dict[baseline_type].keys():\n",
    "        results_dict[baseline_type][environment] = np.stack(results_dict[baseline_type][environment], axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiPaRS results paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_PATH = \"../ipynbs/BiPaRS_partial_results\"\n",
    "LOGS_TEMPLATE_PATH = os.path.join(RESULTS_PATH, \"%s\", \"summary\")\n",
    "\n",
    "BIPARS_LOG_PATH_LIST = [LOGS_TEMPLATE_PATH % folder for folder in os.listdir(RESULTS_PATH) if os.path.isdir(os.path.join(RESULTS_PATH, folder))]\n",
    "BIPARS_LOG_PATH_LIST = sorted([os.path.join(log_path, tb_log_name) for log_path in BIPARS_LOG_PATH_LIST for tb_log_name in os.listdir(log_path)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filepath in BIPARS_LOG_PATH_LIST:\n",
    "    run_name = filepath.split(\"/\")[-3]\n",
    "    baseline_type = \"BiPaRS_\" + \"_\".join(run_name.split(\"_\")[2:4])\n",
    "    environment = run_name.split(\"_\")[-1]\n",
    "    \n",
    "    # print(environment)\n",
    "    \n",
    "    if environment not in results_dict[baseline_type]:\n",
    "        results_dict[baseline_type][environment] = []\n",
    "    \n",
    "    ea = event_accumulator.EventAccumulator(filepath, size_guidance={\"scalars\": 0})\n",
    "    ea.Reload()\n",
    "    \n",
    "    scalars = [scalar.value for scalar in ea.Scalars(\"Test_Episode_Success\")]\n",
    "    scalars = np.interp(np.arange(100) * (len(scalars) / 100), np.arange(len(scalars)), scalars).tolist()\n",
    "    \n",
    "    results_dict[baseline_type][environment].append(scalars)\n",
    "    \n",
    "for baseline_type in results_dict.keys():\n",
    "    for environment in results_dict[baseline_type].keys():\n",
    "        results_dict[baseline_type][environment] = np.stack(results_dict[baseline_type][environment], axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttest(mean_0, mean_1, std_0, std_1, n_0, n_1):\n",
    "    return np.abs(mean_0 - mean_1) / np.sqrt(std_0**2 / n_0 + std_1**2 / n_1)\n",
    "\n",
    "def df(std_0, std_1, n_0, n_1):\n",
    "    return (std_0**2 / n_0 + std_1**2 / n_1)**2 / ((std_0**2 / n_0)**2 / (n_0 - 1) + (std_1**2 / n_1)**2 / (n_1 - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>first_algo</th>\n",
       "      <th>second_algo</th>\n",
       "      <th>first_mean</th>\n",
       "      <th>first_std</th>\n",
       "      <th>significant</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>80</td>\n",
       "      <td>Random</td>\n",
       "      <td>Setter-Solver</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.028447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>99</td>\n",
       "      <td>Random</td>\n",
       "      <td>Setter-Solver</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.025080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>80</td>\n",
       "      <td>Main task</td>\n",
       "      <td>Setter-Solver</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.028447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>99</td>\n",
       "      <td>Main task</td>\n",
       "      <td>Setter-Solver</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.025080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>80</td>\n",
       "      <td>Setter-Solver</td>\n",
       "      <td>Random</td>\n",
       "      <td>0.584242</td>\n",
       "      <td>0.477993</td>\n",
       "      <td>True</td>\n",
       "      <td>0.028447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>99</td>\n",
       "      <td>Setter-Solver</td>\n",
       "      <td>Random</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>True</td>\n",
       "      <td>0.025080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>80</td>\n",
       "      <td>Setter-Solver</td>\n",
       "      <td>Main task</td>\n",
       "      <td>0.584242</td>\n",
       "      <td>0.477993</td>\n",
       "      <td>True</td>\n",
       "      <td>0.028447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>Setter-Solver</td>\n",
       "      <td>Main task</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>True</td>\n",
       "      <td>0.025080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>80</td>\n",
       "      <td>Setter-Solver</td>\n",
       "      <td>ALP-GMM</td>\n",
       "      <td>0.584242</td>\n",
       "      <td>0.477993</td>\n",
       "      <td>True</td>\n",
       "      <td>0.028447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>99</td>\n",
       "      <td>Setter-Solver</td>\n",
       "      <td>ALP-GMM</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>True</td>\n",
       "      <td>0.025080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>80</td>\n",
       "      <td>Setter-Solver</td>\n",
       "      <td>SAC-Q</td>\n",
       "      <td>0.584242</td>\n",
       "      <td>0.477993</td>\n",
       "      <td>True</td>\n",
       "      <td>0.028447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>99</td>\n",
       "      <td>Setter-Solver</td>\n",
       "      <td>SAC-Q</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.489898</td>\n",
       "      <td>True</td>\n",
       "      <td>0.025080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>80</td>\n",
       "      <td>ALP-GMM</td>\n",
       "      <td>Setter-Solver</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.028447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>99</td>\n",
       "      <td>ALP-GMM</td>\n",
       "      <td>Setter-Solver</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.025080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>80</td>\n",
       "      <td>SAC-Q</td>\n",
       "      <td>Setter-Solver</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.028447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>99</td>\n",
       "      <td>SAC-Q</td>\n",
       "      <td>Setter-Solver</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.025080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     step     first_algo    second_algo  first_mean  first_std  significant  \\\n",
       "18     80         Random  Setter-Solver    0.000000   0.000000         True   \n",
       "19     99         Random  Setter-Solver    0.000000   0.000000         True   \n",
       "48     80      Main task  Setter-Solver    0.000000   0.000000         True   \n",
       "49     99      Main task  Setter-Solver    0.000000   0.000000         True   \n",
       "93     80  Setter-Solver         Random    0.584242   0.477993         True   \n",
       "94     99  Setter-Solver         Random    0.600000   0.489898         True   \n",
       "98     80  Setter-Solver      Main task    0.584242   0.477993         True   \n",
       "99     99  Setter-Solver      Main task    0.600000   0.489898         True   \n",
       "113    80  Setter-Solver        ALP-GMM    0.584242   0.477993         True   \n",
       "114    99  Setter-Solver        ALP-GMM    0.600000   0.489898         True   \n",
       "118    80  Setter-Solver          SAC-Q    0.584242   0.477993         True   \n",
       "119    99  Setter-Solver          SAC-Q    0.600000   0.489898         True   \n",
       "138    80        ALP-GMM  Setter-Solver    0.000000   0.000000         True   \n",
       "139    99        ALP-GMM  Setter-Solver    0.000000   0.000000         True   \n",
       "168    80          SAC-Q  Setter-Solver    0.000000   0.000000         True   \n",
       "169    99          SAC-Q  Setter-Solver    0.000000   0.000000         True   \n",
       "\n",
       "            p  \n",
       "18   0.028447  \n",
       "19   0.025080  \n",
       "48   0.028447  \n",
       "49   0.025080  \n",
       "93   0.028447  \n",
       "94   0.025080  \n",
       "98   0.028447  \n",
       "99   0.025080  \n",
       "113  0.028447  \n",
       "114  0.025080  \n",
       "118  0.028447  \n",
       "119  0.025080  \n",
       "138  0.028447  \n",
       "139  0.025080  \n",
       "168  0.028447  \n",
       "169  0.025080  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "at_steps = [20, 40, 60, 80, 99]\n",
    "ignore = {'BiPaRS_v1_fop', 'BiPaRS_v2_fsa'}\n",
    "alpha = 0.05\n",
    "\n",
    "keys_map = {\n",
    "    \"random\": \"Random\",\n",
    "    \"manualtask\": \"Main task\",\n",
    "    \"currot\": \"CurrOT\",\n",
    "    \"settersolver\": \"Setter-Solver\",\n",
    "    \"alpgmm\": \"ALP-GMM\",\n",
    "    \"sacx\": \"SAC-Q\",\n",
    "    # \"BiPaRS_v1_fop\": \"BiPaRS-v1\",\n",
    "    # \"BiPaRS_v2_fsa\": \"BiPaRS-v2\",\n",
    "    # \"BiPaRS_v3_fsart\": \"BiPaRS\"\n",
    "}\n",
    "bonferroni = len(keys_map) - 1\n",
    "\n",
    "column_names = ['step', 'first_algo', 'second_algo', \"first_mean\", \"first_std\", \"significant\", \"p\"]\n",
    "results = pd.DataFrame(columns=column_names)\n",
    "\n",
    "for first_algo in keys_map.keys():\n",
    "    first_scalar_id = list(results_dict[first_algo].keys())[0]\n",
    "    first_data = results_dict[first_algo][first_scalar_id]\n",
    "    for second_algo in keys_map.keys():\n",
    "        if first_algo in ignore or second_algo in ignore:\n",
    "            continue\n",
    "\n",
    "        second_scalar_id = list(results_dict[second_algo].keys())[0]\n",
    "        second_data = results_dict[second_algo][second_scalar_id]\n",
    "        \n",
    "        for step in at_steps:\n",
    "            first_data_selection = first_data[:, step]\n",
    "            second_data_selection = second_data[:, step]\n",
    "            \n",
    "            first_mean = first_data_selection.mean()\n",
    "            first_std = first_data_selection.std()\n",
    "            \n",
    "            second_mean = second_data_selection.mean()\n",
    "            second_std = second_data_selection.std()\n",
    "            \n",
    "            first_n = len(first_data_selection)\n",
    "            second_n = len(second_data_selection)\n",
    "            \n",
    "            # t_scores = ttest(first_mean, second_mean, first_std, second_std, first_n, second_n)\n",
    "            # p_values = stats.t.sf(t_scores, df=df(first_std, second_std, first_n, second_n)) * 2\n",
    "            u_scores = stats.mannwhitneyu(first_data_selection, second_data_selection)\n",
    "            p_values = u_scores.pvalue\n",
    "            \n",
    "            p_values *= bonferroni\n",
    "            significant = p_values < alpha\n",
    "            \n",
    "            results.loc[len(results)] = [step, keys_map[first_algo], keys_map[second_algo], first_mean, first_std, significant, p_values]\n",
    "            \n",
    "results[results.significant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\textcolor{tab:pink}{\\ding{169}} \\textbf{Main task} & \n",
      "0.0 \\par $\\pm$ 0.0\\par  & \n",
      "0.0 \\par $\\pm$ 0.0\\par  & \n",
      "0.0 \\par $\\pm$ 0.0\\par  & \n",
      "0.0 \\par $\\pm$ 0.0\\par \\textcolor{tab:green}{\\ding{169}} & \n",
      "0.0 \\par $\\pm$ 0.0\\par \\textcolor{tab:green}{\\ding{169}} \\\\ \\hline\n",
      "\n",
      "\\textcolor{tab:brown}{\\ding{169}} \\textbf{Random} & \n",
      "0.0 \\par $\\pm$ 0.0\\par  & \n",
      "0.0 \\par $\\pm$ 0.0\\par  & \n",
      "0.0 \\par $\\pm$ 0.0\\par  & \n",
      "0.0 \\par $\\pm$ 0.0\\par \\textcolor{tab:green}{\\ding{169}} & \n",
      "0.0 \\par $\\pm$ 0.0\\par \\textcolor{tab:green}{\\ding{169}} \\\\ \\hline\n",
      "\n",
      "\\textcolor{tab:purple}{\\ding{169}} \\textbf{SAC-Q} & \n",
      "0.0 \\par $\\pm$ 0.0\\par  & \n",
      "0.0 \\par $\\pm$ 0.0\\par  & \n",
      "0.0 \\par $\\pm$ 0.0\\par  & \n",
      "0.0 \\par $\\pm$ 0.0\\par \\textcolor{tab:green}{\\ding{169}} & \n",
      "0.0 \\par $\\pm$ 0.0\\par \\textcolor{tab:green}{\\ding{169}} \\\\ \\hline\n",
      "\n",
      "\\rowcolor{gray!20} \\textcolor{tab:green}{\\ding{169}} \\textbf{Setter-Solver} & \n",
      "0.0 \\par $\\pm$ 0.0\\par  & \n",
      "0.01 \\par $\\pm$ 0.03\\par  & \n",
      "0.34 \\par $\\pm$ 0.41\\par  & \n",
      "0.58 \\par $\\pm$ 0.48\\par \\textcolor{tab:brown}{\\ding{169}}\\textcolor{tab:pink}{\\ding{169}}\\textcolor{tab:blue}{\\ding{169}}\\textcolor{tab:purple}{\\ding{169}} & \n",
      "0.6 \\par $\\pm$ 0.49\\par \\textcolor{tab:brown}{\\ding{169}}\\textcolor{tab:pink}{\\ding{169}}\\textcolor{tab:blue}{\\ding{169}}\\textcolor{tab:purple}{\\ding{169}} \\\\ \\hline\n",
      "\n",
      "\\rowcolor{gray!20} \\textcolor{tab:orange}{\\ding{169}} \\textbf{CurrOT} & \n",
      "0.0 \\par $\\pm$ 0.0\\par  & \n",
      "0.0 \\par $\\pm$ 0.0\\par  & \n",
      "0.0 \\par $\\pm$ 0.01\\par  & \n",
      "0.09 \\par $\\pm$ 0.28\\par  & \n",
      "0.11 \\par $\\pm$ 0.3\\par  \\\\ \\hline\n",
      "\n",
      "\\rowcolor{gray!20} \\textcolor{tab:blue}{\\ding{169}} \\textbf{ALP-GMM} & \n",
      "0.0 \\par $\\pm$ 0.0\\par  & \n",
      "0.0 \\par $\\pm$ 0.0\\par  & \n",
      "0.0 \\par $\\pm$ 0.0\\par  & \n",
      "0.0 \\par $\\pm$ 0.0\\par \\textcolor{tab:green}{\\ding{169}} & \n",
      "0.0 \\par $\\pm$ 0.0\\par \\textcolor{tab:green}{\\ding{169}} \\\\ \\hline\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "algorithms_order = [\"Main task\", \"Random\", \"SAC-Q\", \"Setter-Solver\", \"CurrOT\", \"ALP-GMM\"] # , \"BiPaRS\"]\n",
    "colors = {\n",
    "    \"Random\": \"tab:brown\",\n",
    "    \"Main task\": \"tab:pink\",\n",
    "    \"CurrOT\": \"tab:orange\",\n",
    "    \"Setter-Solver\": \"tab:green\",\n",
    "    \"ALP-GMM\": \"tab:blue\",\n",
    "    \"SAC-Q\": \"tab:purple\",\n",
    "    \"BiPaRS\": \"tab:red\"\n",
    "}\n",
    "\n",
    "gray_rows = {\"CurrOT\", \"Setter-Solver\", \"ALP-GMM\"}\n",
    "symbol = \"\\\\ding{169}\"\n",
    "\n",
    "for algo in algorithms_order:\n",
    "    if algo in gray_rows:\n",
    "        print(\"\\\\rowcolor{gray!20} \", end=\"\")\n",
    "        \n",
    "    print(\"\\\\textcolor{\" + colors[algo] + \"}{\" + symbol + \"}\" + \" \\\\textbf{\" + algo + \"}\", end=\"\")\n",
    "    for step in at_steps:\n",
    "        subset = results[(results.step == step) & (results.first_algo == algo)]\n",
    "        print(\" & \\n\", end=\"\")\n",
    "        \n",
    "        print(np.round(subset.first_mean.iloc[0], 2), \"\\\\par $\\\\pm$\", np.round(subset.first_std.iloc[0], 2), end=\"\")\n",
    "        print(\"\\\\par \", end=\"\")\n",
    "        \n",
    "        if len(subset) > 0:\n",
    "            for index, row in subset.iterrows():\n",
    "                if row.significant:\n",
    "                    print(\"\\\\textcolor{\" + colors[row.second_algo] + \"}{\" + symbol + \"}\", end=\"\")\n",
    "                # print(row.second_algo, row.significant)\n",
    "        # print(\"}\", end=\"\")\n",
    "    print(\" \\\\\\ \\\\hline\\n\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.9\n",
    "alpha = 0.05\n",
    "\n",
    "ignore = {'BiPaRS_v1_fop', 'BiPaRS_v2_fsa'}\n",
    "keys_map = {\n",
    "    \"random\": \"Random\",\n",
    "    \"manualtask\": \"Main task\",\n",
    "    \"currot\": \"CurrOT\",\n",
    "    \"settersolver\": \"Setter-Solver\",\n",
    "    \"alpgmm\": \"ALP-GMM\",\n",
    "    \"sacx\": \"SAC-Q\",\n",
    "    # \"BiPaRS_v1_fop\": \"BiPaRS-v1\",\n",
    "    # \"BiPaRS_v2_fsa\": \"BiPaRS-v2\",\n",
    "    # \"BiPaRS_v3_fsart\": \"BiPaRS\"\n",
    "}\n",
    "\n",
    "bonferroni = len(keys_map) - 1\n",
    "\n",
    "steps_data = OrderedDict()\n",
    "\n",
    "for first_algo in keys_map.keys():\n",
    "    first_scalar_id = list(results_dict[first_algo].keys())[0]\n",
    "    first_data = results_dict[first_algo][first_scalar_id]\n",
    "    \n",
    "    first_above_threshold = np.where(first_data > threshold)\n",
    "    # if len(np.unique(first_above_threshold[0])) != len(first_data): \n",
    "    #     continue\n",
    "    \n",
    "    first_occurences = [np.where(first_above_threshold[0] == idx)[0][0] for idx in range(len(first_data)) if idx in first_above_threshold[0]]\n",
    "    first_algo_indices = first_above_threshold[1][first_occurences]\n",
    "    \n",
    "    for second_algo in keys_map.keys():\n",
    "        if first_algo in ignore or second_algo in ignore or first_algo == second_algo:\n",
    "            continue\n",
    "\n",
    "        second_scalar_id = list(results_dict[second_algo].keys())[0]\n",
    "        second_data = results_dict[second_algo][second_scalar_id]\n",
    "        \n",
    "        second_above_threshold = np.where(second_data > threshold)\n",
    "        # if len(np.unique(second_above_threshold[0])) != len(second_data): \n",
    "        #     continue\n",
    "        \n",
    "        second_occurences = [np.where(second_above_threshold[0] == idx)[0][0] for idx in range(len(second_data)) if idx in second_above_threshold[0]]\n",
    "        second_algo_indices = second_above_threshold[1][second_occurences]\n",
    "        \n",
    "        steps_data[first_algo + \":\" + second_algo] = (first_algo_indices, second_algo_indices)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`x` and `y` must be of nonzero size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m comparison, (first_steps_data, second_steps_data) \u001b[38;5;129;01min\u001b[39;00m steps_data\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 2\u001b[0m     u_scores \u001b[38;5;241m=\u001b[39m \u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmannwhitneyu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_steps_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msecond_steps_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     p_values \u001b[38;5;241m=\u001b[39m u_scores\u001b[38;5;241m.\u001b[39mpvalue\n\u001b[1;32m      5\u001b[0m     p_values \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m bonferroni\n",
      "File \u001b[0;32m~/miniconda3/envs/rew_curr/lib/python3.10/site-packages/scipy/stats/_axis_nan_policy.py:523\u001b[0m, in \u001b[0;36m_axis_nan_policy_factory.<locals>.axis_nan_policy_decorator.<locals>.axis_nan_policy_wrapper\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sentinel:\n\u001b[1;32m    522\u001b[0m     samples \u001b[38;5;241m=\u001b[39m _remove_sentinel(samples, paired, sentinel)\n\u001b[0;32m--> 523\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mhypotest_fun_out\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    524\u001b[0m res \u001b[38;5;241m=\u001b[39m result_to_tuple(res)\n\u001b[1;32m    525\u001b[0m res \u001b[38;5;241m=\u001b[39m _add_reduced_axes(res, reduced_axes, keepdims)\n",
      "File \u001b[0;32m~/miniconda3/envs/rew_curr/lib/python3.10/site-packages/scipy/stats/_mannwhitneyu.py:460\u001b[0m, in \u001b[0;36mmannwhitneyu\u001b[0;34m(x, y, use_continuity, alternative, axis, method)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;129m@_axis_nan_policy_factory\u001b[39m(MannwhitneyuResult, n_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmannwhitneyu\u001b[39m(x, y, use_continuity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, alternative\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtwo-sided\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    251\u001b[0m                  axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    252\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m'''Perform the Mann-Whitney U rank test on two independent samples.\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \n\u001b[1;32m    254\u001b[0m \u001b[38;5;124;03m    The Mann-Whitney U test is a nonparametric test of the null hypothesis\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    456\u001b[0m \n\u001b[1;32m    457\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m    459\u001b[0m     x, y, use_continuity, alternative, axis_int, method \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 460\u001b[0m         \u001b[43m_mwu_input_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_continuity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malternative\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    462\u001b[0m     x, y, xy \u001b[38;5;241m=\u001b[39m _broadcast_concatenate(x, y, axis)\n\u001b[1;32m    464\u001b[0m     n1, n2 \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/rew_curr/lib/python3.10/site-packages/scipy/stats/_mannwhitneyu.py:203\u001b[0m, in \u001b[0;36m_mwu_input_validation\u001b[0;34m(x, y, use_continuity, alternative, axis, method)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`x` and `y` must not contain NaNs.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39msize(x) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39msize(y) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`x` and `y` must be of nonzero size.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    205\u001b[0m bools \u001b[38;5;241m=\u001b[39m {\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m}\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_continuity \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m bools:\n",
      "\u001b[0;31mValueError\u001b[0m: `x` and `y` must be of nonzero size."
     ]
    }
   ],
   "source": [
    "for comparison, (first_steps_data, second_steps_data) in steps_data.items():\n",
    "    u_scores = stats.mannwhitneyu(first_steps_data, second_steps_data)\n",
    "    p_values = u_scores.pvalue\n",
    "    \n",
    "    p_values *= bonferroni\n",
    "    significant = p_values < alpha\n",
    "    print(comparison, np.round(p_values, 2), significant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500000.0\n",
      "Setter-Solver $1.11 \\times 10^5$\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.9\n",
    "\n",
    "ignore = {'BiPaRS_v1_fop', 'BiPaRS_v2_fsa'}\n",
    "keys_map = OrderedDict({\n",
    "    \"manualtask\": \"Main task\",\n",
    "    \"random\": \"Random\",\n",
    "    \"sacx\": \"SAC-Q\",\n",
    "    \"currot\": \"CurrOT\",\n",
    "    \"settersolver\": \"Setter-Solver\",\n",
    "    \"alpgmm\": \"ALP-GMM\",\n",
    "    # \"BiPaRS_v1_fop\": \"BiPaRS-v1\",\n",
    "    # \"BiPaRS_v2_fsa\": \"BiPaRS-v2\",\n",
    "    # \"BiPaRS_v3_fsart\": \"BiPaRS\"\n",
    "})\n",
    "\n",
    "total_steps = 1.5e6\n",
    "print(total_steps)\n",
    "\n",
    "steps_data = OrderedDict()\n",
    "\n",
    "for algo in keys_map.keys():\n",
    "    scalar_id = list(results_dict[algo].keys())[0]\n",
    "    data = results_dict[algo][scalar_id]\n",
    "    \n",
    "    above_threshold = np.where(np.median(data, axis=0) > threshold)\n",
    "    # if len(np.unique(first_above_threshold[0])) != len(first_data): \n",
    "    #     continue\n",
    "    \n",
    "    # first_occurences = [np.where(above_threshold[0] == idx)[0][0] for idx in range(len(data)) if idx in above_threshold[0]]\n",
    "    # indices = above_threshold[1][first_occurences]\n",
    "    \n",
    "    if len(above_threshold[0]) == 0:\n",
    "        continue\n",
    "    \n",
    "    print(keys_map[algo], \"$\" + str((total_steps * above_threshold[0][0] / 100) / 10e5) + \" \\\\times 10^5$\")\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rew_curr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

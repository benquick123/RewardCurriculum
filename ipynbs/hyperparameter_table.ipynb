{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"/home/benjamin/RewardCurriculum/results/panda_pick_and_place_long/2024-02-04_10-30-48_PandaMultiRewardPickAndPlaceDense-v3_tqc_alpgmm_1/config.json\"\n",
    "with open(config_path, 'r') as f:\n",
    "    config_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('environment / env_name', 'PandaMultiRewardPickAndPlaceDense-v3'),\n",
       " ('environment / n_envs', 1),\n",
       " ('environment / wrapper_kwargs', [{'reward_threshold': -0.05}]),\n",
       " ('environment / wrappers', ['SparseRewardWrapper']),\n",
       " ('eval_kwargs / best_model_save_path',\n",
       "  './results/panda_pick_and_place_long/2024-02-04_10-30-48_PandaMultiRewardPickAndPlaceDense-v3_tqc_alpgmm_1/evaluations'),\n",
       " ('eval_kwargs / eval_freq', 5000),\n",
       " ('eval_kwargs / log_path',\n",
       "  './results/panda_pick_and_place_long/2024-02-04_10-30-48_PandaMultiRewardPickAndPlaceDense-v3_tqc_alpgmm_1/evaluations'),\n",
       " ('eval_kwargs / n_eval_episodes', 10),\n",
       " ('learner_class', \"<class '.TQC'>\"),\n",
       " ('learner_kwargs / batch_size', 2048),\n",
       " ('learner_kwargs / buffer_size', 1500000),\n",
       " ('learner_kwargs / device', 'cuda'),\n",
       " ('learner_kwargs / ent_coef', 'auto'),\n",
       " ('learner_kwargs / gamma', 0.95),\n",
       " ('learner_kwargs / gradient_steps', -1),\n",
       " ('learner_kwargs / learning_rate', 0.001),\n",
       " ('learner_kwargs / learning_starts', 10000),\n",
       " ('learner_kwargs / policy_kwargs / n_critics', 2),\n",
       " ('learner_kwargs / policy_kwargs / net_arch / ext', [64, 64]),\n",
       " ('learner_kwargs / policy_kwargs / net_arch / pi', [512, 512, 512]),\n",
       " ('learner_kwargs / policy_kwargs / net_arch / qf', [512, 512, 512]),\n",
       " ('learner_kwargs / reward_dim', 3),\n",
       " ('learner_kwargs / scheduler_class', \"<class '.ALPGMM'>\"),\n",
       " ('learner_kwargs / scheduler_kwargs / fitting_buffer_size', 100),\n",
       " ('learner_kwargs / scheduler_kwargs / gmm_fitness_fn', 'aic'),\n",
       " ('learner_kwargs / scheduler_kwargs / nb_bootstrap', 5),\n",
       " ('learner_kwargs / scheduler_kwargs / nb_neighbours', 3),\n",
       " ('learner_kwargs / scheduler_kwargs / potential_clusters', [1, 11, 1]),\n",
       " ('learner_kwargs / scheduler_kwargs / random_task_ratio', 0.2),\n",
       " ('learner_kwargs / scheduler_kwargs / seed', 3),\n",
       " ('learner_kwargs / scheduler_kwargs / tau', 10),\n",
       " ('learner_kwargs / scheduler_kwargs / update_frequency', 50),\n",
       " ('learner_kwargs / scheduler_kwargs / update_weights_frequency', 10),\n",
       " ('learner_kwargs / seed', 2),\n",
       " ('learner_kwargs / target_update_interval', 1),\n",
       " ('learner_kwargs / tau', 0.05),\n",
       " ('learner_kwargs / tensorboard_log',\n",
       "  './results/panda_pick_and_place_long/2024-02-04_10-30-48_PandaMultiRewardPickAndPlaceDense-v3_tqc_alpgmm_1/tb'),\n",
       " ('learner_kwargs / train_freq', [1, 'episode']),\n",
       " ('log',\n",
       "  '2024-02-04_10-30-48_PandaMultiRewardPickAndPlaceDense-v3_tqc_alpgmm_1'),\n",
       " ('log_model_interval', False),\n",
       " ('log_path', './results/panda_pick_and_place_long'),\n",
       " ('seed', 1),\n",
       " ('tb_log_name', 'PandaMultiRewardPickAndPlaceDense-v3_tqc_alpgmm_1'),\n",
       " ('train_kwargs / log_interval', 20),\n",
       " ('train_kwargs / progress_bar', True),\n",
       " ('train_kwargs / total_timesteps', 1500000)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_data(data, prefix=''):\n",
    "    extracted_data = []\n",
    "    for key, value in data.items():\n",
    "        if isinstance(value, dict):\n",
    "            extracted_data.extend(extract_data(value, prefix=f'{prefix}{key} / '))\n",
    "        else:\n",
    "            extracted_data.append((f'{prefix}{key}', value))\n",
    "    return extracted_data\n",
    "\n",
    "extracted_data = extract_data(config_data)\n",
    "extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{ll}\n",
      "\\hline\n",
      " Key                                                          & Value                                                                                                                 \\\\\n",
      "\\hline\n",
      " environment / env\\_name                                       & PandaMultiRewardPickAndPlaceDense-v3                                                                                  \\\\\n",
      " environment / n\\_envs                                         & 1                                                                                                                     \\\\\n",
      " environment / wrapper\\_kwargs                                 & [\\{'reward\\_threshold': -0.05\\}]                                                                                         \\\\\n",
      " environment / wrappers                                       & ['SparseRewardWrapper']                                                                                               \\\\\n",
      " eval\\_kwargs / best\\_model\\_save\\_path                           & ./results/panda\\_pick\\_and\\_place\\_long/2024-02-04\\_10-30-48\\_PandaMultiRewardPickAndPlaceDense-v3\\_tqc\\_alpgmm\\_1/evaluations \\\\\n",
      " eval\\_kwargs / eval\\_freq                                      & 5000                                                                                                                  \\\\\n",
      " eval\\_kwargs / log\\_path                                       & ./results/panda\\_pick\\_and\\_place\\_long/2024-02-04\\_10-30-48\\_PandaMultiRewardPickAndPlaceDense-v3\\_tqc\\_alpgmm\\_1/evaluations \\\\\n",
      " eval\\_kwargs / n\\_eval\\_episodes                                & 10                                                                                                                    \\\\\n",
      " learner\\_class                                                & \\ensuremath{<}class '.TQC'\\ensuremath{>}                                                                                                        \\\\\n",
      " learner\\_kwargs / batch\\_size                                  & 2048                                                                                                                  \\\\\n",
      " learner\\_kwargs / buffer\\_size                                 & 1500000                                                                                                               \\\\\n",
      " learner\\_kwargs / device                                      & cuda                                                                                                                  \\\\\n",
      " learner\\_kwargs / ent\\_coef                                    & auto                                                                                                                  \\\\\n",
      " learner\\_kwargs / gamma                                       & 0.95                                                                                                                  \\\\\n",
      " learner\\_kwargs / gradient\\_steps                              & -1                                                                                                                    \\\\\n",
      " learner\\_kwargs / learning\\_rate                               & 0.001                                                                                                                 \\\\\n",
      " learner\\_kwargs / learning\\_starts                             & 10000                                                                                                                 \\\\\n",
      " learner\\_kwargs / policy\\_kwargs / n\\_critics                   & 2                                                                                                                     \\\\\n",
      " learner\\_kwargs / policy\\_kwargs / net\\_arch / ext              & [64, 64]                                                                                                              \\\\\n",
      " learner\\_kwargs / policy\\_kwargs / net\\_arch / pi               & [512, 512, 512]                                                                                                       \\\\\n",
      " learner\\_kwargs / policy\\_kwargs / net\\_arch / qf               & [512, 512, 512]                                                                                                       \\\\\n",
      " learner\\_kwargs / reward\\_dim                                  & 3                                                                                                                     \\\\\n",
      " learner\\_kwargs / scheduler\\_class                             & \\ensuremath{<}class '.ALPGMM'\\ensuremath{>}                                                                                                     \\\\\n",
      " learner\\_kwargs / scheduler\\_kwargs / fitting\\_buffer\\_size      & 100                                                                                                                   \\\\\n",
      " learner\\_kwargs / scheduler\\_kwargs / gmm\\_fitness\\_fn           & aic                                                                                                                   \\\\\n",
      " learner\\_kwargs / scheduler\\_kwargs / nb\\_bootstrap             & 5                                                                                                                     \\\\\n",
      " learner\\_kwargs / scheduler\\_kwargs / nb\\_neighbours            & 3                                                                                                                     \\\\\n",
      " learner\\_kwargs / scheduler\\_kwargs / potential\\_clusters       & [1, 11, 1]                                                                                                            \\\\\n",
      " learner\\_kwargs / scheduler\\_kwargs / random\\_task\\_ratio        & 0.2                                                                                                                   \\\\\n",
      " learner\\_kwargs / scheduler\\_kwargs / seed                     & 3                                                                                                                     \\\\\n",
      " learner\\_kwargs / scheduler\\_kwargs / tau                      & 10                                                                                                                    \\\\\n",
      " learner\\_kwargs / scheduler\\_kwargs / update\\_frequency         & 50                                                                                                                    \\\\\n",
      " learner\\_kwargs / scheduler\\_kwargs / update\\_weights\\_frequency & 10                                                                                                                    \\\\\n",
      " learner\\_kwargs / seed                                        & 2                                                                                                                     \\\\\n",
      " learner\\_kwargs / target\\_update\\_interval                      & 1                                                                                                                     \\\\\n",
      " learner\\_kwargs / tau                                         & 0.05                                                                                                                  \\\\\n",
      " learner\\_kwargs / tensorboard\\_log                             & ./results/panda\\_pick\\_and\\_place\\_long/2024-02-04\\_10-30-48\\_PandaMultiRewardPickAndPlaceDense-v3\\_tqc\\_alpgmm\\_1/tb          \\\\\n",
      " learner\\_kwargs / train\\_freq                                  & [1, 'episode']                                                                                                        \\\\\n",
      " log                                                          & 2024-02-04\\_10-30-48\\_PandaMultiRewardPickAndPlaceDense-v3\\_tqc\\_alpgmm\\_1                                                 \\\\\n",
      " log\\_model\\_interval                                           & False                                                                                                                 \\\\\n",
      " log\\_path                                                     & ./results/panda\\_pick\\_and\\_place\\_long                                                                                   \\\\\n",
      " seed                                                         & 1                                                                                                                     \\\\\n",
      " tb\\_log\\_name                                                  & PandaMultiRewardPickAndPlaceDense-v3\\_tqc\\_alpgmm\\_1                                                                     \\\\\n",
      " train\\_kwargs / log\\_interval                                  & 20                                                                                                                    \\\\\n",
      " train\\_kwargs / progress\\_bar                                  & True                                                                                                                  \\\\\n",
      " train\\_kwargs / total\\_timesteps                               & 1500000                                                                                                               \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "table = tabulate(extracted_data, headers=[\"Key\", \"Value\"], tablefmt=\"latex\")\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rew_curr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
